= Workflow management with Airflow

The management of the workflow is made available through the user
interface of the Airflow system. This section describes the provided
pipelines, and how to operate them in Airflow.

== Airflow DAG control board

In this section we explain the most important elements to pay attention
to when operating the pipelines. +
In software engineering, a pipeline consists of a chain of processing
elements (processes, threads, coroutines, functions, etc.), arranged so
that the output of each element is the input of the next. In our case,
as an example, look at the notice_processing_pipeline, which has this
chain of processes that takes as input a notice from the TED website and
as the final output (if every process from this pipeline runs
successfully) a METS package with a transformed notice in the RDF
format. Between the processes the input will always be a batch of
notices. Batch processing is a method of processing large amounts of
data in a single, pre-defined process. Batch processing is typically
used for tasks that are performed periodically, such as daily, weekly,
or monthly. Each step of the pipeline can have a successful or failure
result, and as such the pipeline can be stopped at any step if something
went wrong with one of its processes. In Airflow terminology a pipeline
will be a DAG. He are the processes that will create our
notice_processing_pipeline DAG:

* notice normalisation
* notice transformation
* notice distillation
* notice validation
* notice packaging
* notice publishing

=== Enable / disable switch

In Airflow all the DAGs can be enabled or disabled. If a dag is disabled
that will stop the DAG from running even if that DAG is scheduled.

When a dag is enabled the switch button will be blue and grey when it is
disabled.

To enable or disable a dag use the following switch button:

image:user_manual/media/image21.png[image,width=100%,height=32]

image:user_manual/media/image69.png[image,width=56,height=55]
disabled position

image:user_manual/media/image3.png[image,width=52,height=56]
enabled position

=== DAG Runs

A DAG Run is an object representing an instantiation of the DAG in time.
Any time the DAG is executed, a DAG Run is created and all tasks inside
it are executed. The status of the DAG Run depends on the tasks states.
Each DAG Run is run separately from one another, meaning that you can
have many runs of a DAG at the same time.

DAG Run Status

A DAG Run status is determined when the execution of the DAG is
finished. The execution of the DAG depends on its containing tasks and
their dependencies. The status is assigned to the DAG Run when all of
the tasks are in one of the terminal states (i.e. if there is no
possible transition to another state) like success, failed or skipped.

There are two possible terminal states for the DAG Run:

* success if all the pipeline processes are either success or skipped,
* failed if any of the pipeline processes is either failed or
upstream_failed.

In the runs column in the Airflow user interface we can see the state of
the DAG run, and this can be one of the following:

* queued
* success
* running
* failed


Here is an example of this different states

image:user_manual/media/image54.png[image,width=422,height=315]

The transitions for these states will start from queuing, then will go
to running, and after will either go to success or failure.

Clicking on the numbers associated with a particular DAG run state will
show you a list of the DAG runs in that state.

=== DAG actions

In the Airflow user interface we have a run button in the Actions column
that will allow you to trigger a specific DAG with or without specific
configuration. When clicking on the run button a list of options will
appear:

* Trigger DAG (triggering DAG without config)
* Trigger DAG w/ config (triggering DAG with config)


image:user_manual/media/image24.png[image,width=378,height=165]

=== DAG Run overview

In the Airflow user interface, when clicking on the DAG name, an
overview of the runs for that DAG will be available. This will include
schema of the processes that are a part of the pipeline, task durations,
code for the DAG, etc. To learn more about Airflow interface please
refer to the Airflow user manual
(link:#useful-resources[[.underline]#Useful Resources#])

image:user_manual/media/image74.png[image,width=601,height=281]



== Available pipelines

In this section we provide a brief inventory of provided pipelines
including their names, a short description and a high level diagram.

[arabic]

=== notice_processing_pipeline
This DAG performs the processing of a
batch of notices, where the stages take place: normalization,
transformation, validation, packaging, publishing. This is scheduled and
automatically started by other DAGs.


image:user_manual/media/image31.png[image,width=100%,height=176]

image:user_manual/media/image25.png[image,width=100%,height=162]


[arabic, start=2]

=== load_mapping_suite_in_database

This DAG performs the loading of a mapping suite or all mapping suites from a branch on GitHub, with the mapping suite the test data from it can also be loaded, if the test data
is loaded the notice_processing_pipeline DAG will be triggered.



*Config DAG params:*


* mapping_suite_package_name: string
* load_test_data: boolean
* branch_or_tag_name: string
* github_repository_url: string

*Default values:*

* mapping_suite_package_name = None (it will take all available mapping
suites on that branch or tag)
* load_test_data = false
* branch_or_tag_name = "main"
* github_repository_url= "https://github.com/OP-TED/ted-rdf-mapping.git"


image:user_manual/media/image96.png[image,width=100%,height=56]

=== fetch_notices_by_query
This DAG fetches notices from TED by using a query and, depending on an additional parameter, triggers the notice_processing_pipeline DAG in full or partial mode (execution of
only one step).

*Config DAG params:*

* query : string
* trigger_complete_workflow : boolean

*Default values:*

* trigger_complete_workflow = true

image:user_manual/media/image56.png[image,width=100%,height=92]

===  fetch_notices_by_date

This DAG fetches notices from TED for a day and, depending on an additional parameter, triggers the notice_processing_pipeline DAG in full or partial mode (execution of only one step).

*Config DAG params:*

* wild_card : string with date format %Y%m%d*
* trigger_complete_workflow : boolean

*Default values:*

* trigger_complete_workflow = true

image:user_manual/media/image33.png[image,width=100%,height=100]

=== fetch_notices_by_date_range

This DAG receives a date range and triggers the fetch_notices_by_date DAG for each day in the date range.

*Config DAG params:*

* start_date : string with date format %Y%m%d
* end_date : string with date format %Y%m%d

image:user_manual/media/image75.png[image,width=601,height=128]

===  reprocess_unnormalised_notices_from_backlog

This DAG selects all notices that are in RAW state and need to be processed and triggers the
notice_processing_pipeline DAG to process them.

*Config DAG params:*

* start_date : string with date format %Y-%m-%d
* end_date : string with date format %Y-%m-%d

*Default values:*

* start_date = None , because this param is optional
* end_date = None, because this param is optional

image:user_manual/media/image60.png[image,width=601,height=78]

image:user_manual/media/image106.png[image,width=100%,height=70]

=== reprocess_unpackaged_notices_from_backlog

This DAG selects all notices to be repackaged and triggers the notice_processing_pipeline DAG
to repackage them.

*Config DAG params:*

* start_date : string with date format %Y-%m-%d
* end_date : string with date format %Y-%m-%d
* form_number : string
* xsd_version : string

*Default values:*

* start_date = None , because this param is optional
* end_date = None, because this param is optional
* form_number = None, because this param is optional
* xsd_version = None, because this param is optional

image:user_manual/media/image81.png[image,width=100%,height=73]

image:user_manual/media/image107.png[image,width=100%,height=70]

===  reprocess_unpublished_notices_from_backlog

This DAG selects all notices to be republished and triggers the notice_processing_pipeline
DAG to republish them.

*Config DAG params:*


* start_date : string with date format %Y-%m-%d
* end_date : string with date format %Y-%m-%d
* form_number : string
* xsd_version : string

*Default values:*


* start_date = None, because this param is optional
* end_date = None, because this param is optional
* form_number = None, because this param is optional
* xsd_version = None, because this param is optional

image:user_manual/media/image37.png[image,width=100%,height=70]

image:user_manual/media/image108.png[image,width=100%,height=70]

===  reprocess_untransformed_notices_from_backlog

This DAG selects all notices to be retransformed and triggers the notice_processing_pipeline
DAG to retransform them.

*Config DAG params:*


* start_date : string with date format %Y-%m-%d
* end_date : string with date format %Y-%m-%d
* form_number : string
* xsd_version : string

*Default values:*

* start_date = None , because this param is optional
* end_date = None, because this param is optional
* form_number = None, because this param is optional
* xsd_version = None, because this param is optional


image:user_manual/media/image102.png[image,width=100%,height=69]

image:user_manual/media/image105.png[image,width=100%,height=70]

===  reprocess_unvalidated_notices_from_backlog

This DAG selects all notices to be revalidated and triggers the notice_processing_pipeline
DAG to revalidate them.

*Config DAG params:*

* start_date : string with date format %Y-%m-%d
* end_date : string with date format %Y-%m-%d
* form_number : string
* xsd_version : string

*Default values:*


* start_date = None , because this param is optional
* end_date = None, because this param is optional
* form_number = None, because this param is optional
* xsd_version = None, because this param is optional

image:user_manual/media/image102.png[image,width=100%,height=69]

image:user_manual/media/image105.png[image,width=100%,height=70]

=== daily_materialized_views_update

This DAG selects all notices to be revalidated and triggers the notice_processing_pipeline DAG to
revalidate them.

*This DAG has no config or default params.*

image:user_manual/media/image98.png[image,width=100%,height=90]

=== daily_check_notices_availability_in_cellar

This DAG selects all notices to be revalidated and triggers the notice_processing_pipeline
DAG to revalidate them.

*This DAG has no config or default params.*

image:user_manual/media/image67.png[image,width=339,height=81]

=== reprocess_published_in_cellar_notices

This DAG selects publicly available notices that shall be retransformed and triggers the notice_processing_pipeline DAG to republish them.

*Config DAG params:*

* start_date : string with date format %Y-%m-%d
* end_date : string with date format %Y-%m-%d
* form_number : string
* xsd_version : string

*Default values:*


* start_date = None , because this param is optional
* end_date = None, because this param is optional
* form_number = None, because this param is optional
* xsd_version = None, because this param is optional

image:user_manual/media/image102.png[image,width=100%,height=69]

image:user_manual/media/image105.png[image,width=100%,height=70]


== Batch processing

== Running pipelines (How to)

This chapter explains the basic utilization of Ted SWS Airflow pipelines
by presenting in the format of answering the questions. Basic
functionality can be used by running DAGs: a core concept of Airflow.
For advanced documentation access:

https://airflow.apache.org/docs/apache-airflow/stable/concepts/dags.html[[.underline]#https://airflow.apache.org/docs/apache-airflow/stable/concepts/DAGs.html#]

=== UC1: How to load a mapping suite or mapping suites?

As a user I want to load one or several mapping suites into the system
so that notices can be transformed and validated with them.

=== UC1.a To load all mapping suites

[arabic]
. Run *load_mapping_suite_in_database* DAG:
[loweralpha]
.. Enable DAG
.. Click Run on Actions column (Play symbol button)
.. Click Trigger DAG


image:user_manual/media/image84.png[image,width=100%,height=61]

=== UC1.b To load specific mapping suite

[arabic]
. Run *load_mapping_suite_in_database* DAG with configurations:
[loweralpha]
.. Enable DAG
.. Click Run on Actions column (Play symbol button)
.. Click Trigger DAG w/ config.

image:user_manual/media/image36.png[image,width=100%,height=55]

[arabic, start=2]
. In the next screen

[loweralpha]
. In the configuration JSON text box insert the config:

[source,python]
{"mapping_suite_package_name": "package_F03"}

[loweralpha, start=2]
. Click Trigger button after inserting the configuration

image:user_manual/media/image27.png[image,width=100%,height=331]

[arabic, start=3]
. Optional if you want to transform the available test notices that were
used for development of the mapping suite you can add to configuration
the *load_test_data* parameter with the value *true*

image:user_manual/media/image103.png[image,width=100%,height=459]

=== UC2: How to fetch and process notices for a day?

As a user I want to fetch and process notices from a selected day so
that they get published in Cellar and be available to the public in RDF
format.

UC2.a To fetch and transform notices for a day:

[arabic]
. Enable *notice_processing_pipeline* DAG
. Run *fetch_notices_by_date* DAG with configurations:
[loweralpha]
.. Enable DAG
.. Click Run on Actions column
.. Click Trigger DAG w/ config

image:user_manual/media/image26.png[image,width=100%,height=217]

[arabic, start=3]
. In the next screen

[loweralpha]
. In the configuration JSON text box insert the config:
[source,python]
{"wild_card ": "20220921*"}*

The value *20220921** is the date of the day to fetch and transform with
format: yyyymmdd*.


[loweralpha, start=2]
. Click Trigger button after inserting the configuration

image:user_manual/media/image1.png[image,width=100%,height=310]

[arabic, start=4]
. Optional: It is possible to only fetch notices without transformation.
To do so add *trigger_complete_workflow* configuration parameter and set
its value to “false”. +
[source,python]
{"wild_card ": "20220921*", "trigger_complete_workflow": false}

image:user_manual/media/image4.png[image,width=100%,height=358]


=== UC3: How to fetch and process notices for date range?

As a user I want to fetch and process notices published within a dare
range so that they are published in Cellar and available to the public
in RDF format.

UC3.a To fetch for multiple days:

[arabic]
. Enable *notice_processing_pipeline* DAG
. Run *fetch_notices_by_date_range* DAG with configurations:
[loweralpha]
.. Enable DAG
.. Click Run on Actions column
.. Click Trigger DAG w/ config.

image:user_manual/media/image79.png[image,width=100%,height=205]

[arabic, start=3]
. In the next screen, in the configuration JSON text box insert the
config:
[source,python]
{ "start_date": "20220920", "end_date": "20220920" }

20220920 is the start date and 20220920 is the end date of the days to
be fetched and transformed with format: yyyymmdd.

[arabic, start=4]
. Click Trigger button after inserting the configuration

image:user_manual/media/image51.png[image,width=100%,height=331]

=== UC4: How to fetch and process notices using a query?

As a user I want to fetch and process notices published by specific
filters that are available from the TED API so that they are published
in Cellar and available to the public in RDF format.

To fetch and transform notices by using a query follow the instructions
below:

[arabic]
. Enable *notice_processing_pipeline* DAG
. Run *fetch_notices_by_query* DAG with configurations:
.. Enable DAG
.. Click Run on Actions column
.. Click Trigger DAG w/ config.

image:user_manual/media/image61.png[image,width=100%,height=200]
[arabic, start=3]
. In the next screen

[loweralpha]
. In the configuration JSON text box insert the config:

[source,python]
{"query": "ND=[163-2021]"}


ND=[163-2021] is the query that will run against the TED API to get
notices that will match that query

[loweralpha, start=2]
. Click Trigger button after inserting the configuration

image:user_manual/media/image93.png[image,width=100%,height=378]

[arabic, start=4]
. Optional: If you need to only fetch notices without
transformation, add *trigger_complete_workflow* configuration as *false*

image:user_manual/media/image49.png[image,width=100%,height=357]

=== UC5: How to deal with notices that are in the backlog and what to run?

As a user I want to reprocess notices that are in the backlog so that
they are published in Cellar and available to the public in RDF format.

Notices that have failed running a complete and successful notice_processing_pipeline run will be added to the backlog by using different statuses that will be added to these notices. The status of a notice will be automatically determined by the system. The backlog could
have multiple notices in different statuses.

The backlog is divided in five categories as follows:

* notices that couldn’t be normalised
* notices that couldn’t be transformed
* notices that couldn’t be validated
* notices that couldn’t be packaged
* notices that couldn’t be published

==== UC5.a Deal with notices that couldn't be normalised

In the case that the backlog contains notices that couldn’t be normalised at some point and will want to try to reprocess those notices just run the *reprocess_unnormalised_notices_from_backlog* DAG following the instructions below.

[arabic]
. Enable the reprocess_unnormalised_notices_from_backlog DAG

image:user_manual/media/image92.png[image,width=100%,height=44]

[arabic, start=2]
. Trigger DAG

image:user_manual/media/image76.png[image,width=100%,height=54]

==== UC5.b: Deal with notices that couldn't be transformed

In the case that the backlog contains notices that couldn’t be transformed at some point and will want to try to reprocess those notices just run the *reprocess_untransformed_notices_from_backlog* DAG following the instructions below.

[arabic]
. Enable the reprocess_untransformed_notices_from_backlog DAG
image:user_manual/media/image85.png[image,width=100%,height=36]

[arabic, start=2]
. Trigger DAG

image:user_manual/media/image77.png[image,width=100%,height=54]

==== UC5.c: Deal with notices that couldn’t be validated

In the case that the backlog contains notices that couldn’t be validated at some point and will want to try to reprocess those notices just run the *reprocess_unvalidated_notices_from_backlog* DAG following the instructions below.

[arabic]
. Enable the reprocess_unvalidated_notices_from_backlog DAG

image:user_manual/media/image66.png[image,width=100%,height=41]

[arabic, start=2]
. Trigger DAG

image:user_manual/media/image52.png[image,width=100%,height=52]

==== UC5.d: Deal with notices that couldn't be packages

In the case that the backlog contains notices that could not be packaged at some point and will want to try to reprocess those notices just run the *reprocess_unpackaged_notices_from_backlog* DAG following the instructions below.

[arabic]
. Enable the reprocess_unpackaged_notices_from_backlog DAG

image:user_manual/media/image29.png[image,width=100%,height=36]

[arabic, start=2]
. Trigger DAG

image:user_manual/media/image71.png[image,width=100%,height=49]

==== UC5.e: Deal with notices that couldn't be published

In the case that the backlog contains notices that couldn’t be published at some point and will want to try to reprocess those notices just run the  *reprocess_unpublished_notices_from_backlog* DAG following the instructions below.

[arabic]
. Enable the reprocess_unpublished_notices_from_backlog DAG

image:user_manual/media/image38.png[image,width=100%,height=38]

[arabic, start=2]
. Trigger DAG

image:user_manual/media/image19.png[image,width=100%,height=57]

=== UC6: How to re-transform notices that have been successfully published and publicly available ?

As a user I want to re-transform notices that have been successfully published and publicly available so that new versions of the RDF notices are published in Cellar and available to the public in RDF format.

This use cases is appropriate only when a new version of the Mapping suite has been loaded into the TED-SWS system. Otherwise, the output of the re-transformation will be the same as before.


[arabic]
. Enable the *reprocess_published_in_cellar_notices* DAG

image:user_manual/media/image109.png[image,width=100%,height=38]

[arabic, start=2]
. Trigger DAG

image:user_manual/media/image19.png[image,width=100%,height=57]

== Scheduled pipelines

Scheduled pipelines are DAGs that are set to run periodically at fixed
times, dates, or intervals. The DAG schedule can be read in the column
“Schedule” and if any is set then the value is different from None.
The scheduled execution is indicated as “cron expressions” [cire cron
expressions manual]. A cron expression is a string comprising five or
six fields separated by white space that represents a set of times,
normally as a schedule to execute some routine. In our context examples
of daily executions are provided below.

image:user_manual/media/image34.png[image,width=83,height=365,]

* None - DAG with no Schedule
* 0 0 * * * - DAG that will run every day at 24:00 UTC
* 0 6 * * * - DAG that will run every day at 06:00 UTC
* 0 1 * * * - DAG that will run every day at 01:00 UTC

== Operational rules and recommendations

Note: Every action that was not described in the previous chapters can
lead to unpredictable situations.

* Do not stop a DAG when it is in running state. Let it finish. In case
you need to disable or stop a DAG, then make sure that in the column
Recent Tasks no numbers in the light green circle are present. Figure
below depicts one such example.
image:user_manual/media/image72.png[image,width=601,height=164]

* Do not run reprocess DAGs when notice_processing_pipeline is in running
state. This will produce errors as the reprocessing DAGs are searching
for notices in a specific status available in the database. When the
notice_processing_pipeline is running the notices are transitioning
between different statuses and that will make it possible to get the
same notice to be processed twice in the same time, which will produce
an error. Make sure that in the column Runs for
notice_processing_pipeline you don’t have any numbers in a light green
circle before running any reprocess DAGs.
image:user_manual/media/image30.png[image,width=601,height=162]


* Do not manually trigger notice_processing_pipeline as this DAG is
triggered automatically by other DAGs. This will produce an error as
this DAG needs to know what batch of notices it is processing (this is
automatically done by the system). This DAG should only be enabled.
image:user_manual/media/image18.png[image,width=602,height=29]

* To start any notice processing and transformation make sure that you
have mapping suites available in the database. You should have at least
one successful run of the *load_mapping_suite_in_database* DAG and check
Metabase to see what mapping suites are available.
image:user_manual/media/image32.png[image,width=653,height=30]

* Do not manually trigger scheduled DAGs unless you use a specific
configuration and that DAG supports running with specific configuration.
The scheduled dags should be only enabled.
image:user_manual/media/image87.png[image,width=601,height=77]

* It is not recommended to load mapping suites while
notice_processing_pipeline is running. First make sure that there are no
running tasks and then load other mapping suites.
image:user_manual/media/image35.png[image,width=601,height=256] {nbsp}
image:user_manual/media/image91.png[image,width=601,height=209]

* It is recommended to start processing / transforming notices for a short
period of time e.g fetch notices for a day, week, month but not year.
The system can handle processing for a longer period but it will take
time and you will not be able to load other mapping suites while
processing is running.
